{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import sqrt, e, log\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_margin(x, alpha, h):\n",
    "    \"\"\"\n",
    "    Calculate the margin of a point\n",
    "    Args:\n",
    "        x:      point\n",
    "        alpha:  weights\n",
    "        h:      classifiers\n",
    "    \"\"\"\n",
    "    alpha_l1 = np.linalg.norm(alpha, ord=1)\n",
    "    T = len(h)\n",
    "    f = 0\n",
    "    for i in range(T):\n",
    "        f = alpha[i] * h[i].predict(x)\n",
    "    margin = np.abs(f) / alpha_l1\n",
    "    return margin\n",
    "\n",
    "def sample_margin(X, alpha, h):\n",
    "    \"\"\"\n",
    "    Calculate the margin of a sample\n",
    "    Args:\n",
    "        X:      sample\n",
    "        alpha:  weights\n",
    "        h:      classifiers\n",
    "    \"\"\"\n",
    "    m = X.shape[0]\n",
    "    margin = float('+inf')\n",
    "    for i in range(m):\n",
    "        x = X[i].reshape(1, -1)\n",
    "        margin = min(margin, point_margin(x, alpha, h))\n",
    "    return margin\n",
    "\n",
    "def get_error_bound(rho, d, m, delta):\n",
    "    \"\"\"\n",
    "    Calculate the error bound\n",
    "    Args:\n",
    "        rho:    margin\n",
    "        d:      VC dimension\n",
    "        m:      sample size\n",
    "        delta:  confidence\n",
    "    \"\"\"\n",
    "    first_term = sqrt((2 * d * log(e * m / d)) / m) * 2 / rho\n",
    "    second_term = sqrt(log(1 / delta) / (2 * m))\n",
    "    return first_term + second_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22676960597684473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.487819, 0.48818700000000004, array([0.03954692]), array([0.81605038]))"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = 10\n",
    "m = 1000000\n",
    "delta = 0.3\n",
    "\n",
    "# print(get_error_bound(0.14, d, m, delta))\n",
    "\n",
    "def create_dataset(m, d):\n",
    "    \"\"\"\n",
    "    Create a dataset for the experiment\n",
    "    Args:\n",
    "        m: sample size\n",
    "        d: VC dimension\n",
    "    \"\"\"\n",
    "    X, y = make_classification(\n",
    "        n_samples=2*m,\n",
    "        n_features=d-1,\n",
    "        n_classes=2,\n",
    "        random_state=42,\n",
    "        shuffle=False,\n",
    "        class_sep=0.2,\n",
    "    )\n",
    "    # Changle class labels to +1 and -1\n",
    "    y = 2*y - 1\n",
    "    # Split the dataset into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.5, random_state=42\n",
    "    )\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def evaluate_error(m, d, delta):\n",
    "    \"\"\"\n",
    "    Evaluate the error of the AdaBoost classifier\n",
    "    Args:\n",
    "        m:      sample size\n",
    "        d:      VC dimension\n",
    "        delta:  confidence\n",
    "        T:      number of iterations\n",
    "    \"\"\"\n",
    "    # Create the dataset\n",
    "    X_train, X_test, y_train, y_test = create_dataset(m, d)\n",
    "\n",
    "    # Train the AdaBoostClassifier with Perceptron base estimator\n",
    "    clf = AdaBoostClassifier(\n",
    "        base_estimator=Perceptron(penalty=None),\n",
    "        # n_estimators=T,\n",
    "        algorithm='SAMME',\n",
    "        random_state=20,\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    alpha = clf.estimator_weights_\n",
    "    h = clf.estimators_\n",
    "    rho = sample_margin(X_train, alpha, h)\n",
    "\n",
    "    R_test = 1 - clf.score(X_test, y_test)\n",
    "    R_train = 1 - clf.score(X_train, y_train)\n",
    "    error_bound = get_error_bound(rho, d, m, delta)\n",
    "\n",
    "    return R_test, R_train, error_bound, rho\n",
    "\n",
    "evaluate_error(m, d, delta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40fe40b7a1c6001628267b17b49c7a3b91f89c63956810a1e7a8974171e1f2d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
